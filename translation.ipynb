{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN73uCALfQ/nsEQ2vOaqWAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-codebr0/Yash-codebr0/blob/main/translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "0B4uuVTgxBQm",
        "outputId": "266bb2d6-d21c-4996-bc91-ae91164f55a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# translate eng_to_chi\n",
        "from transformers import MarianMTModel,MarianTokenizer\n",
        "\n",
        "#load the tokenizer and model\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-zh\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "def translate_en_to_zh(sentence):\n",
        "  inputs = tokenizer(sentence, return_tensors=\"pt\",padding=True)\n",
        "  translate = model.generate(**inputs)\n",
        "  translated_text = tokenizer.decode(translate[0],skip_special_tokens=True)\n",
        "  return translated_text\n",
        "\n",
        "print(translate_en_to_zh(\"Hello World\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translate from en to any lang\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "def translate(text,target_lang_code):\n",
        "  tokenizer.src_lang = \"eng_Latn\"\n",
        "\n",
        "  #set target lang\n",
        "  inputs = tokenizer(text,return_tensors=\"pt\")\n",
        "\n",
        "  # generate tokens, getting forced bos token id\n",
        "  forced_bos_token_id = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(target_lang_code))[0]\n",
        "\n",
        "  # Generate translation\n",
        "  generated_tokens = model.generate(\n",
        "      **inputs,\n",
        "      forced_bos_token_id=forced_bos_token_id,\n",
        "      max_length=100\n",
        "  )\n",
        "\n",
        "  translate_text = tokenizer.decode(generated_tokens[0],skip_special_tokens=True)\n",
        "  return translate_text\n",
        "\n",
        "language_map = {\n",
        "    \"chinese\":\"zho_Hans\",\n",
        "    \"english\":\"en_Latn\",\n",
        "    \"french\":\"fra_Latn\",\n",
        "    \"german\":\"deu_Latn\",\n",
        "    \"japanese\":\"jpn_Latn\",\n",
        "    \"espanol\":\"spa_Latn\",\n",
        "    \"italian\":\"ita_Latn\",\n",
        "    \"russian\":\"rus_Cyrl\",\n",
        "    \"norwa;\":\"nld_Latn\",\n",
        "    \"arabi\":\"arb_Arab\",\n",
        "    \"hindi\":\"hin_Deva\",\n",
        "}\n",
        "\n",
        "text_to_translate = input(\"Enter text: \")\n",
        "target_lang = input(f\"Enter target language ({', '.join(language_map.keys())}): \")\n",
        "if target_lang  in language_map:\n",
        "  target_lang = language_map[target_lang]\n",
        "  translated = translate(text_to_translate, target_lang)\n",
        "  print(f\"Translated text: {translated}\")\n",
        "else:\n",
        "  print(\"Invalid language code\")"
      ],
      "metadata": {
        "id": "IWt761O00Qti"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}